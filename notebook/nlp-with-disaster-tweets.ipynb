{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T14:54:20.177834Z","iopub.execute_input":"2025-05-12T14:54:20.178057Z","iopub.status.idle":"2025-05-12T14:54:20.460249Z","shell.execute_reply.started":"2025-05-12T14:54:20.178038Z","shell.execute_reply":"2025-05-12T14:54:20.459502Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load the datasets\ntrain_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n\n# Quick look at the data\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T14:56:45.448535Z","iopub.execute_input":"2025-05-12T14:56:45.448861Z","iopub.status.idle":"2025-05-12T14:56:45.549468Z","shell.execute_reply.started":"2025-05-12T14:56:45.448839Z","shell.execute_reply":"2025-05-12T14:56:45.548787Z"}},"outputs":[{"name":"stdout","text":"Train shape: (7613, 5)\nTest shape: (3263, 4)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_df['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:02:28.595798Z","iopub.execute_input":"2025-05-12T15:02:28.596693Z","iopub.status.idle":"2025-05-12T15:02:28.608381Z","shell.execute_reply.started":"2025-05-12T15:02:28.596664Z","shell.execute_reply":"2025-05-12T15:02:28.607628Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import re\nimport string\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"http\\S+\",\"\",text) # Remove URLs\n    text = re.sub(r\"@\\w+\",\"\",text) # Remove mentions\n    text = re.sub(r\"#\",\"\",text) # Remove Hastag symbol\n    text = re.sub(r\"[^\\w\\s]\",\"\",text) # Remove punctuation\n    text = re.sub(r\"\\d+\",\"\",text) # Remove Numbers\n    return text\n\ntrain_df['clean_text'] = train_df['text'].apply(clean_text)\ntest_df['clean_text'] = test_df['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:09:22.181726Z","iopub.execute_input":"2025-05-12T15:09:22.182223Z","iopub.status.idle":"2025-05-12T15:09:22.267631Z","shell.execute_reply.started":"2025-05-12T15:09:22.182200Z","shell.execute_reply":"2025-05-12T15:09:22.267131Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words= 'english', max_features=5000)\nx_train = vectorizer.fit_transform(train_df['clean_text'])\nx_test = vectorizer.transform(test_df['clean_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:12:26.855195Z","iopub.execute_input":"2025-05-12T15:12:26.855991Z","iopub.status.idle":"2025-05-12T15:12:27.059102Z","shell.execute_reply.started":"2025-05-12T15:12:26.855962Z","shell.execute_reply":"2025-05-12T15:12:27.058421Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(x_train, train_df['target'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:21:09.409361Z","iopub.execute_input":"2025-05-12T15:21:09.409953Z","iopub.status.idle":"2025-05-12T15:21:09.630362Z","shell.execute_reply.started":"2025-05-12T15:21:09.409932Z","shell.execute_reply":"2025-05-12T15:21:09.629788Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"preds = model.predict(x_test)\nsubmission_df['target'] = preds\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:22:25.053817Z","iopub.execute_input":"2025-05-12T15:22:25.054084Z","iopub.status.idle":"2025-05-12T15:22:25.067975Z","shell.execute_reply.started":"2025-05-12T15:22:25.054067Z","shell.execute_reply":"2025-05-12T15:22:25.067420Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(model, x_train, train_df['target'],cv=5,scoring='accuracy').mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:23:59.332170Z","iopub.execute_input":"2025-05-12T15:23:59.332497Z","iopub.status.idle":"2025-05-12T15:24:00.099004Z","shell.execute_reply.started":"2025-05-12T15:23:59.332476Z","shell.execute_reply":"2025-05-12T15:24:00.098476Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.6956599767213717"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n\ntrain_df['clean_text'] = train_df['clean_text'].apply(lemmatize_text)\ntest_df['clean_text'] = test_df['clean_text'].apply(lemmatize_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:24:46.587180Z","iopub.execute_input":"2025-05-12T15:24:46.587953Z","iopub.status.idle":"2025-05-12T15:24:50.306459Z","shell.execute_reply.started":"2025-05-12T15:24:46.587931Z","shell.execute_reply":"2025-05-12T15:24:50.305873Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_df['keyword'] = train_df['keyword'].fillna('')\ntest_df['keyword'] = test_df['keyword'].fillna('')\ntrain_df['location'] = train_df['location'].fillna('')\ntest_df['location'] = test_df['location'].fillna('')\n\n\ntrain_df['combined'] = train_df['clean_text'] + \" \" + train_df['keyword'] + \" \" + train_df['location']\ntest_df['combined'] = test_df['clean_text'] + \" \" + test_df['keyword'] + \" \" + test_df['location']\n\n\nX_train = vectorizer.fit_transform(train_df['combined'])\nX_test = vectorizer.transform(test_df['combined'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:24:58.104816Z","iopub.execute_input":"2025-05-12T15:24:58.105520Z","iopub.status.idle":"2025-05-12T15:24:58.263331Z","shell.execute_reply.started":"2025-05-12T15:24:58.105498Z","shell.execute_reply":"2025-05-12T15:24:58.262802Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, train_df['target'])\nrf_preds = rf_model.predict(X_test)\nsubmission_df['target'] = rf_preds\nsubmission_df.to_csv('submission_rf.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:25:28.241260Z","iopub.execute_input":"2025-05-12T15:25:28.241841Z","iopub.status.idle":"2025-05-12T15:25:35.332912Z","shell.execute_reply.started":"2025-05-12T15:25:28.241819Z","shell.execute_reply":"2025-05-12T15:25:35.332360Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.toarray())  \nX_test_scaled = scaler.transform(X_test.toarray())\n\nmodel = LogisticRegression(max_iter=500, solver='lbfgs')  \nmodel.fit(X_train_scaled, train_df['target'])\npredictions = model.predict(X_test_scaled)\nsubmission_df['target'] = predictions\nsubmission_df.to_csv('submission_logistic_regression.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:28:24.031879Z","iopub.execute_input":"2025-05-12T15:28:24.032582Z","iopub.status.idle":"2025-05-12T15:28:46.452042Z","shell.execute_reply.started":"2025-05-12T15:28:24.032552Z","shell.execute_reply":"2025-05-12T15:28:46.451469Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n\ntrain_predictions = model.predict(X_train_scaled)\nprint(\"Training Accuracy: \", accuracy_score(train_df['target'], train_predictions))\nprint(\"Classification Report:\\n\", classification_report(train_df['target'], train_predictions))\n\n\nif 'target' in submission_df.columns:\n    test_predictions = model.predict(X_test_scaled)\n    print(\"Test Accuracy: \", accuracy_score(submission_df['target'], test_predictions))\n    print(\"Test Classification Report:\\n\", classification_report(submission_df['target'], test_predictions))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:29:20.702281Z","iopub.execute_input":"2025-05-12T15:29:20.702946Z","iopub.status.idle":"2025-05-12T15:29:20.788075Z","shell.execute_reply.started":"2025-05-12T15:29:20.702924Z","shell.execute_reply":"2025-05-12T15:29:20.787483Z"}},"outputs":[{"name":"stdout","text":"Training Accuracy:  0.9888348876921056\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      4342\n           1       0.99      0.98      0.99      3271\n\n    accuracy                           0.99      7613\n   macro avg       0.99      0.99      0.99      7613\nweighted avg       0.99      0.99      0.99      7613\n\nTest Accuracy:  1.0\nTest Classification Report:\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      1810\n           1       1.00      1.00      1.00      1453\n\n    accuracy                           1.00      3263\n   macro avg       1.00      1.00      1.00      3263\nweighted avg       1.00      1.00      1.00      3263\n\n","output_type":"stream"}],"execution_count":22}]}